{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "88325efe6e1e90c58e37029f398efd794ecd7ecc"
   },
   "source": [
    "# 1. SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import os\n",
    "import time\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tsfresh\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTION 4\n",
    "def remove_bands(df):\n",
    "    \n",
    "    ##### INDIVIDUAL VARIABLES\n",
    "    \n",
    "    # extract some bands\n",
    "    t2 = df.loc[:, df.columns.str.endswith('_p2')].divide(3)\n",
    "    t3 = df.loc[:, df.columns.str.endswith('_p3')].divide(3)\n",
    "    t4 = df.loc[:, df.columns.str.endswith('_p4')].divide(3)\n",
    "\n",
    "    # rename columns\n",
    "    t2.columns = [col.replace(\"_p2\", \"_p234\") for col in t2.columns]\n",
    "    t3.columns = [col.replace(\"_p3\", \"_p234\") for col in t3.columns]\n",
    "    t4.columns = [col.replace(\"_p4\", \"_p234\") for col in t4.columns]\n",
    "\n",
    "    # average\n",
    "    t234 = t2.add(t3)\n",
    "    t234 = t234.add(t4)\n",
    "\n",
    "    # remove individual bands\n",
    "    df = df.loc[:, ~df.columns.str.endswith('_p2')]\n",
    "    df = df.loc[:, ~df.columns.str.endswith('_p3')]\n",
    "    df = df.loc[:, ~df.columns.str.endswith('_p4')]\n",
    "\n",
    "    # merge averaged band\n",
    "    df = pd.concat([df, t234], axis = 1)\n",
    "    \n",
    "    \n",
    "    ##### PASSBAND RATIOS\n",
    "    \n",
    "    # extract some bands\n",
    "    t2 = df.filter(like = 'p2_p0').divide(3)\n",
    "    t3 = df.filter(like = 'p3_p0').divide(3)\n",
    "    t4 = df.filter(like = 'p4_p0').divide(3)\n",
    "\n",
    "    # rename columns\n",
    "    t2.columns = [col.replace(\"p2_p0\", \"p234_p0\") for col in t2.columns]\n",
    "    t3.columns = [col.replace(\"p3_p0\", \"p234_p0\") for col in t3.columns]\n",
    "    t4.columns = [col.replace(\"p4_p0\", \"p234_p0\") for col in t4.columns]\n",
    "\n",
    "    # average\n",
    "    t234 = t2.add(t3)\n",
    "    t234 = t234.add(t4)\n",
    "\n",
    "    # remove individual bands\n",
    "    #drops = list(df.filter(like = 'p2_p0').columns) + list(df.filter(like = 'p3_p0').columns) + list(df.filter(like = 'p4_p0').columns)\n",
    "    #keeps = [f for f in df.columns if f not in drops]\n",
    "    #df = df[keeps]\n",
    "\n",
    "    # merge averaged band\n",
    "    df = pd.concat([df, t234], axis = 1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTION 5\n",
    "def add_dist_ratios(df):\n",
    "    \n",
    "    # compute ratios\n",
    "    df['dist_by_med_flux_p0'] = df['distmod'] - df['flux_median_p0']\n",
    "    df['dist_by_med_flux_p1'] = df['distmod'] - df['flux_median_p1']\n",
    "    df['dist_by_med_flux_p2'] = df['distmod'] - df['flux_median_p2']\n",
    "    df['dist_by_med_flux_p3'] = df['distmod'] - df['flux_median_p3']\n",
    "    df['dist_by_med_flux_p4'] = df['distmod'] - df['flux_median_p4']\n",
    "    df['dist_by_med_flux_p5'] = df['distmod'] - df['flux_median_p5']\n",
    "       \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "587f72a72010fb4fda2531642aff592e0f68cab1"
   },
   "source": [
    "# 2. DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d819975ac7b393b1787a975f79b5feccaf8a81dc"
   },
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "8c44c8a51973f096bc126ce235936f9ff0248a9c"
   },
   "source": [
    "### IMPORT READY DATA\n",
    "full_train = pd.read_csv('../input/full_train_v10.csv')\n",
    "full_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### AGGREGATED FLUX\n",
    "\n",
    "# import and merge\n",
    "aggflux = pd.read_csv('../input/agg_flux_train.csv')\n",
    "full_train = full_train.merge(aggflux, how = 'left', on = 'object_id')\n",
    "del aggflux\n",
    "full_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### CESIUM FEATURES\n",
    "\n",
    "# import new feats\n",
    "ces = pd.read_csv('../input/cesium_train.csv')\n",
    "ces.columns = ['object_id'] + ['ces_' + l.replace('__', '')[:-1] for l in list(ces.columns) if l not in 'object_id']\n",
    "\n",
    "# filter features\n",
    "ces_feats = ['object_id'] + list(ces.filter(like = 'max_slope').columns) + \\\n",
    "                            list(ces.filter(like = 'qso').columns) + \\\n",
    "                            list(ces.filter(like = 'percent_close_to_median').columns)\n",
    "ces = ces[ces_feats]\n",
    "\n",
    "# merge data\n",
    "full_train = full_train.merge(ces, how = 'left', on = 'object_id')\n",
    "del ces\n",
    "full_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### COMPUTE DIST RATIOS\n",
    "full_train = add_dist_ratios(full_train)\n",
    "full_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### REMOVE BANDS\n",
    "full_train = remove_bands(full_train)\n",
    "full_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "2b6f79b71d0e9b62266a52d9e7ac209c56e14aff"
   },
   "source": [
    "### PREPARATIONS\n",
    "\n",
    "# target encoding\n",
    "if 'target' in full_train:\n",
    "    y = full_train['target']\n",
    "    del full_train['target']\n",
    "    \n",
    "full_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d819975ac7b393b1787a975f79b5feccaf8a81dc"
   },
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "8c44c8a51973f096bc126ce235936f9ff0248a9c"
   },
   "source": [
    "### IMPORT READY DATA\n",
    "full_test = pd.read_csv('../input/full_test_v10.csv')\n",
    "full_test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### AGGREGATED FLUX\n",
    "\n",
    "# import and merge\n",
    "aggflux = pd.read_csv('../input/agg_flux_test.csv')\n",
    "full_test = full_test.merge(aggflux, how = 'left', on = 'object_id')\n",
    "del aggflux\n",
    "full_test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### CESIUM FEATURES\n",
    "\n",
    "# import new feats\n",
    "ces = pd.read_csv('../input/cesium_test.csv')\n",
    "ces.columns = ['object_id'] + ['ces_' + l.replace('(\\'', '')[:-1].replace('\\', ', '_') for l in list(ces.columns) if l not in 'object_id']\n",
    "\n",
    "# filter features\n",
    "ces_feats = ['object_id'] + list(ces.filter(like = 'max_slope').columns) + \\\n",
    "                            list(ces.filter(like = 'qso').columns) + \\\n",
    "                            list(ces.filter(like = 'percent_close_to_median').columns)\n",
    "ces = ces[ces_feats]\n",
    "\n",
    "# merge data\n",
    "full_test = full_test.merge(ces, how = 'left', on = 'object_id')\n",
    "del ces\n",
    "full_test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### COMPUTE DIST RATIOS\n",
    "full_test = add_dist_ratios(full_test)\n",
    "full_test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### REMOVE BANDS\n",
    "full_test = remove_bands(full_test)\n",
    "full_test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "2b6f79b71d0e9b62266a52d9e7ac209c56e14aff"
   },
   "source": [
    "### PREPARATIONS\n",
    "\n",
    "# drop some features\n",
    "full_test = full_test[list(full_train.columns)]\n",
    "full_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d819975ac7b393b1787a975f79b5feccaf8a81dc"
   },
   "source": [
    "## MERGER AND SCALING"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# shapes\n",
    "print(full_train.shape)\n",
    "print(full_test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# concatenate\n",
    "data = pd.concat([full_train, full_test], axis = 0)\n",
    "del full_train\n",
    "del full_test\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# export\n",
    "data.to_csv('../input/data_v10_merged.csv', index = False)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500738, 422)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### IMPORT READY DATA\n",
    "data = pd.read_csv('../input/data_v10_merged.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some features\n",
    "oof_df = data[['object_id']]\n",
    "del data['object_id'], data['hostgal_specz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute inf & null\n",
    "data.replace(to_replace = [-np.inf, np.inf], value = np.nan, inplace = True)\n",
    "data_mean = data.median(axis = 0, skipna = True)\n",
    "data.fillna(data_mean, inplace = True)\n",
    "data = data.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500738, 420)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rescale\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "ss = MinMaxScaler()\n",
    "data = ss.fit_transform(data)\n",
    "data = pd.DataFrame(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a0fd0de1bcd933e5bc32384283eb5325f1959f1b"
   },
   "source": [
    "# 3. AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Reshape\n",
    "from keras import regularizers\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "encoding_dim = 30\n",
    "num_epochs   = 50\n",
    "num_batch    = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear session\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AUTOENCODER\n",
    "\n",
    "# dimensions\n",
    "input_dim = data.shape[1]\n",
    "\n",
    "# architecture type\n",
    "autoencoder = Sequential()\n",
    "\n",
    "# encoder layers\n",
    "autoencoder.add(Dense(4 * encoding_dim, input_shape = (input_dim,), activation = 'relu'))\n",
    "autoencoder.add(Dense(2 * encoding_dim, activation = 'relu'))\n",
    "autoencoder.add(Dense(encoding_dim, activation = 'relu'))\n",
    "\n",
    "# decoder layers\n",
    "autoencoder.add(Dense(2 * encoding_dim, activation = 'relu'))\n",
    "autoencoder.add(Dense(4 * encoding_dim, activation = 'relu'))\n",
    "autoencoder.add(Dense(input_dim, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENCODER PART\n",
    "\n",
    "# dimensions\n",
    "input_img = Input(shape = (input_dim, ))\n",
    "\n",
    "# encoder layers\n",
    "encoder_layer1 = autoencoder.layers[0]\n",
    "encoder_layer2 = autoencoder.layers[1]\n",
    "encoder_layer3 = autoencoder.layers[2]\n",
    "encoder = Model(input_img, encoder_layer3(encoder_layer2(encoder_layer1(input_img))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3500738/3500738 [==============================] - 465s 133us/step - loss: 0.3426\n",
      "Epoch 2/50\n",
      "3500738/3500738 [==============================] - 520s 148us/step - loss: 0.3409\n",
      "Epoch 4/50\n",
      "3500738/3500738 [==============================] - 575s 164us/step - loss: 0.3408\n",
      "Epoch 5/50\n",
      "3500738/3500738 [==============================] - 576s 164us/step - loss: 0.3408\n",
      "Epoch 6/50\n",
      " 309750/3500738 [=>............................] - ETA: 9:52 - loss: 0.340"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380250/3500738 [===================>..........] - ETA: 3:06 - loss: 0.340"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2876750/3500738 [=======================>......]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500738/3500738 [==============================] - 560s 160us/step - loss: 0.3408\n",
      "Epoch 7/50\n",
      "3500738/3500738 [==============================] - 562s 161us/step - loss: 0.3408\n",
      "Epoch 8/50\n",
      "1968500/3500738 [===============>..............] - ETA: 3:57 - loss: 0.3407"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3487000/3500738 [============================>.]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500738/3500738 [==============================] - 549s 157us/step - loss: 0.3407\n",
      "Epoch 11/50\n",
      " 595500/3500738 [====>.........................] - ETA: 7:22 - loss: 0.3407"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2401500/3500738 [===================>..........] - ETA: 2:41 - loss: 0.3407"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500738/3500738 [==============================] - 487s 139us/step - loss: 0.3407\n",
      "Epoch 14/50\n",
      "3500738/3500738 [==============================] - 418s 119us/step - loss: 0.3407\n",
      "Epoch 15/50\n",
      "3500738/3500738 [==============================] - 415s 119us/step - loss: 0.3407\n",
      "Epoch 16/50\n",
      " 120250/3500738 [>.............................]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500738/3500738 [==============================] - 416s 119us/step - loss: 0.3407\n",
      "Epoch 17/50\n",
      "3500738/3500738 [==============================] - 414s 118us/step - loss: 0.3407\n",
      "Epoch 19/50\n",
      "1186000/3500738 [=========>....................] - ETA: 4:33 - loss: 0.3407"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2816000/3500738 [=======================>......] - ETA: 1:21 - loss: 0.3407"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500738/3500738 [==============================] - 415s 118us/step - loss: 0.3407\n",
      "Epoch 20/50\n",
      "3500738/3500738 [==============================] - 416s 119us/step - loss: 0.3407\n",
      "Epoch 21/50\n",
      "2613000/3500738 [=====================>........] - ETA: 2:08 - loss: 0.3407"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2671750/3500738 [=====================>........] - ETA: 2:00 - loss: 0.3407\n",
      " 358750/3500738 [==>...........................] - ETA: 7:43 - loss: 0.3407"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 890000/3500738 [======>.......................]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500738/3500738 [==============================] - 470s 134us/step - loss: 0.3407\n",
      "Epoch 23/50\n",
      "3486250/3500738 [============================>.] - ETA: 2s - loss: 0.3407"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500738/3500738 [==============================] - 463s 132us/step - loss: 0.3407\n",
      "Epoch 26/50\n",
      "2767250/3500738 [======================>.......] - ETA: 1:46 - loss: 0.3407"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 635500/3500738 [====>.........................] - ETA: 6:42 - loss: 0.3407"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500738/3500738 [==============================] - 468s 134us/step - loss: 0.3407\n",
      "Epoch 29/50\n",
      "3500738/3500738 [==============================] - 504s 144us/step - loss: 0.3407\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1681500/3500738 [=============>................] - ETA: 4:27 - loss: 0.3407"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500738/3500738 [==============================] - 496s 142us/step - loss: 0.3407\n",
      "Epoch 32/50\n",
      "3500738/3500738 [==============================] - 454s 130us/step - loss: 0.3407\n",
      "Epoch 33/50\n",
      " 757500/3500738 [=====>........................] - ETA: 5:25 - loss: 0.3407"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2173500/3500738 [=================>............] - ETA: 2:36 - loss: 0.3407"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500738/3500738 [==============================] - 413s 118us/step - loss: 0.3407\n",
      "Epoch 36/50\n",
      "3500738/3500738 [==============================] - 414s 118us/step - loss: 0.3407\n",
      "Epoch 37/50\n",
      "1882000/3500738 [===============>..............] - ETA: 3:11 - loss: 0.3406"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 392250/3500738 [==>...........................] - ETA: 6:07 - loss: 0.3406"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500738/3500738 [==============================] - 412s 118us/step - loss: 0.3406\n",
      "Epoch 40/50\n",
      "1309500/3500738 [==========>...................]"
     ]
    }
   ],
   "source": [
    "### MODELING\n",
    "\n",
    "# compile\n",
    "autoencoder.compile(optimizer = 'adam', loss = 'binary_crossentropy')\n",
    "\n",
    "# fit\n",
    "autoencoder.fit(data, data,\n",
    "                epochs     = num_epochs,\n",
    "                batch_size = num_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "oof_preds = encoder.predict(data)\n",
    "preds = pd.DataFrame(oof_preds)\n",
    "preds.columns = ['auto' + str(l) for l in list(preds.columns)]\n",
    "preds.insert(loc = 0, column = 'object_id', value = oof_df.object_id.reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.to_csv('../input/auto_f30_b250_e50.csv', index = False)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a0fd0de1bcd933e5bc32384283eb5325f1959f1b"
   },
   "source": [
    "# 4. CV"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# cross-validation\n",
    "folds = KFold(n_splits     = 10, \n",
    "              shuffle      = True,\n",
    "              random_state = 23)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### CROSS-VALIDATION LOOP\n",
    "\n",
    "# create objects\n",
    "oof_preds = np.zeros((len(data), encoding_dim))\n",
    "\n",
    "# modeling loop\n",
    "start  = time.time()\n",
    "for fold_, (trn_, val_) in enumerate(folds.split(data, np.zeros(len(data)))):\n",
    "    \n",
    "    ### PREPARATIONS\n",
    "    \n",
    "    # set epochs\n",
    "    if str(fold_ + 1) == 1:\n",
    "        epochs = num_epochs\n",
    "    else:\n",
    "        epochs = 10\n",
    "    \n",
    "    # clear session\n",
    "    #K.clear_session()\n",
    "    \n",
    "    # data partitioning\n",
    "    trn_x = data.iloc[trn_]\n",
    "    val_x = data.iloc[val_]\n",
    "    \n",
    "    \n",
    "    ### AUTOENCODER\n",
    "\n",
    "    # dimensions\n",
    "    input_dim = trn_x.shape[1]\n",
    "\n",
    "    # architecture type\n",
    "    autoencoder = Sequential()\n",
    "\n",
    "    # encoder layers\n",
    "    autoencoder.add(Dense(4 * encoding_dim, input_shape = (input_dim,), activation = 'relu'))\n",
    "    autoencoder.add(Dense(2 * encoding_dim, activation = 'relu'))\n",
    "    autoencoder.add(Dense(encoding_dim, activation = 'relu'))\n",
    "\n",
    "    # decoder layers\n",
    "    autoencoder.add(Dense(2 * encoding_dim, activation = 'relu'))\n",
    "    autoencoder.add(Dense(4 * encoding_dim, activation = 'relu'))\n",
    "    autoencoder.add(Dense(input_dim, activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "    ### ENCODER PART\n",
    "\n",
    "    # dimensions\n",
    "    input_img = Input(shape = (input_dim, ))\n",
    "\n",
    "    # encoder layers\n",
    "    encoder_layer1 = autoencoder.layers[0]\n",
    "    encoder_layer2 = autoencoder.layers[1]\n",
    "    encoder_layer3 = autoencoder.layers[2]\n",
    "    encoder = Model(input_img, encoder_layer3(encoder_layer2(encoder_layer1(input_img))))\n",
    "    \n",
    "    \n",
    "    ### MODELING\n",
    "    \n",
    "    # compile\n",
    "    autoencoder.compile(optimizer = 'adam', loss = 'binary_crossentropy')\n",
    "    \n",
    "    # fit\n",
    "    autoencoder.fit(trn_x, trn_x,\n",
    "                epochs          = epochs,\n",
    "                batch_size      = num_batch,\n",
    "                validation_data = (val_x, val_x))\n",
    "\n",
    "    # feedback\n",
    "    print('-------------------------------------')\n",
    "    print('FINISHED FOLD ' + str(fold_ + 1))  \n",
    "    print('-------------------------------------')\n",
    "    print('')\n",
    "    \n",
    "    # predictions\n",
    "    oof_preds[val_, :] = encoder.predict(val_x)\n",
    "    \n",
    "    # clean up\n",
    "    gc.collect()\n",
    "    \n",
    "# print performance\n",
    "print('')\n",
    "print('Done in %5.1f minutes' % ((time.time() - start) / 60))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "preds = pd.DataFrame(oof_preds)\n",
    "preds.columns = ['auto' + str(l) for l in list(preds.columns)]\n",
    "preds.insert(loc = 0, column = 'object_id', value = oof_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
